{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training script for tiny-imagenet.\n",
    "# Again, this script has a lot of bugs everywhere.\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import losses\n",
    "\n",
    "from models.discriminators.snresnet64 import Omniglot_Discriminator, VGG_Discriminator, Animal_Discriminator\n",
    "from models.generators.resnet64 import Omniglot_Generator, VGG_Generator, Animal_Generator\n",
    "\n",
    "from dataloader import omniglot_data_loader, vgg_data_loader, img_dataloder, celeba_data_loader\n",
    "import utils\n",
    "from torch.nn.utils import spectral_norm\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_ROTATIONS = 4\n",
    "\n",
    "# Copied from https://github.com/naoto0804/pytorch-AdaIN/blob/master/sampler.py#L5-L15\n",
    "def InfiniteSampler(n):\n",
    "    # i = 0\n",
    "    i = n - 1\n",
    "    order = np.random.permutation(n)\n",
    "    while True:\n",
    "        yield order[i]\n",
    "        i += 1\n",
    "        if i >= n:\n",
    "            np.random.seed()\n",
    "            order = np.random.permutation(n)\n",
    "            i = 0\n",
    "\n",
    "\n",
    "# Copied from https://github.com/naoto0804/pytorch-AdaIN/blob/master/sampler.py#L18-L26\n",
    "class InfiniteSamplerWrapper(data.sampler.Sampler):\n",
    "    def __init__(self, data_source):\n",
    "        self.num_samples = len(data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(InfiniteSampler(self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return 2 ** 31\n",
    "\n",
    "\n",
    "def decay_lr(opt, max_iter, start_iter, initial_lr):\n",
    "    \"\"\"Decay learning rate linearly till 0.\"\"\"\n",
    "    coeff = -initial_lr / (max_iter - start_iter)\n",
    "    for pg in opt.param_groups:\n",
    "        pg['lr'] += coeff\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--exp_version\", type=str, default=\"3-shot_vgg_0.0002\")\n",
    "    parser.add_argument('--dataset', type=str, default=\"vgg\", help=\"omniglot or vgg\")\n",
    "    parser.add_argument('--dataset_root', type=str, default=\"/home/userB/yonggyukim/data\")\n",
    "    parser.add_argument('--n_shot', type=str, default=\"3-shot\")\n",
    "\n",
    "    parser.add_argument('--lr', type=float, default=0.0002,\n",
    "                        help='Initial learning rate of Adam. default: 0.0002')\n",
    "    parser.add_argument('--lr_decay_start', '-lds', type=int, default=50000,\n",
    "                        help='Start point of learning rate decay. default: 50000')\n",
    "\n",
    "    # Dataset configuration\n",
    "    parser.add_argument('--cGAN', default=True, action='store_true',\n",
    "                        help='to train cGAN, set this ``True``. default: False')\n",
    "    parser.add_argument('--data_root', type=str, default='tiny-imagenet-200',\n",
    "                        help='path to dataset root directory. default: tiny-imagenet-200')\n",
    "    parser.add_argument('--batch_size', '-B', type=int, default=64,\n",
    "                        help='mini-batch size of training data. default: 64')\n",
    "    parser.add_argument('--eval_batch_size', '-eB', default=None,\n",
    "                        help='mini-batch size of evaluation data. default: None')\n",
    "    parser.add_argument('--num_workers', type=int, default=8,\n",
    "                        help='Number of workers for training data loader. default: 8')\n",
    "    # Generator configuration\n",
    "    parser.add_argument('--gen_num_features', '-gnf', type=int, default=32,\n",
    "                        help='Number of features of generator (a.k.a. nplanes or ngf). default: 64')\n",
    "    parser.add_argument('--gen_dim_z', '-gdz', type=int, default=128,\n",
    "                        help='Dimension of generator input noise. default: 128')\n",
    "    parser.add_argument('--gen_bottom_width', '-gbw', type=int, default=7,\n",
    "                        help='Initial size of hidden variable of generator. default: 4')\n",
    "    parser.add_argument('--gen_distribution', '-gd', type=str, default='normal',\n",
    "                        help='Input noise distribution: normal (default) or uniform.')\n",
    "    # Discriminator (Critic) configuration\n",
    "    parser.add_argument('--dis_arch_concat', '-concat', default=False, action='store_true',\n",
    "                        help='If use concat discriminator, set this true. default: False')\n",
    "    parser.add_argument('--dis_emb', type=int, default=128,\n",
    "                        help='Parameter for concat discriminator. default: 128')\n",
    "    parser.add_argument('--dis_num_features', '-dnf', type=int, default=32,\n",
    "                        help='Number of features of discriminator (a.k.a nplanes or ndf). default: 64')\n",
    "    # Optimizer settings\n",
    "    parser.add_argument('--beta1', type=float, default=0.0,\n",
    "                        help='beta1 (betas[0]) value of Adam. default: 0.0')\n",
    "    parser.add_argument('--beta2', type=float, default=0.9,\n",
    "                        help='beta2 (betas[1]) value of Adam. default: 0.9')\n",
    "    # Training setting\n",
    "    parser.add_argument('--seed', type=int, default=46,\n",
    "                        help='Random seed. default: 46 (derived from Nogizaka46)')\n",
    "    parser.add_argument('--max_iteration', '-N', type=int, default=100000,\n",
    "                        help='Max iteration number of training. default: 100000')\n",
    "    parser.add_argument('--n_dis', type=int, default=5,\n",
    "                        help='Number of discriminator updater per generator updater. default: 5')\n",
    "    parser.add_argument('--num_classes', '-nc', type=int, default=0,\n",
    "                        help='Number of classes in training data. No need to set. default: 0')\n",
    "    parser.add_argument('--loss_type', type=str, default='hinge',\n",
    "                        help='loss function name. hinge (default) or dcgan.')\n",
    "    parser.add_argument('--relativistic_loss', '-relloss', default=False, action='store_true',\n",
    "                        help='Apply relativistic loss or not. default: False')\n",
    "    parser.add_argument('--calc_FID', default=False, action='store_true',\n",
    "                        help='If calculate FID score, set this ``True``. default: False')\n",
    "    # Log and Save interval configuration\n",
    "    parser.add_argument('--results_root', type=str, default='results',\n",
    "                        help='Path to results directory. default: results')\n",
    "    parser.add_argument('--no_tensorboard', action='store_true', default=False,\n",
    "                        help='If you dislike tensorboard, set this ``False``. default: True')\n",
    "    parser.add_argument('--no_image', action='store_true', default=False,\n",
    "                        help='If you dislike saving images on tensorboard, set this ``True``. default: False')\n",
    "    parser.add_argument('--checkpoint_interval', '-ci', type=int, default=1000,\n",
    "                        help='Interval of saving checkpoints (model and optimizer). default: 1000')\n",
    "    parser.add_argument('--log_interval', '-li', type=int, default=100,\n",
    "                        help='Interval of showing losses. default: 100')\n",
    "    parser.add_argument('--eval_interval', '-ei', type=int, default=100,\n",
    "                        help='Interval for evaluation (save images and FID calculation). default: 1000')\n",
    "    parser.add_argument('--n_eval_batches', '-neb', type=int, default=100,\n",
    "                        help='Number of mini-batches used in evaluation. default: 100')\n",
    "    parser.add_argument('--n_fid_images', '-nfi', type=int, default=50,\n",
    "                        help='Number of images to calculate FID. default: 5000')\n",
    "    parser.add_argument('--test', default=False, action='store_true',\n",
    "                        help='If test this python program, set this ``True``. default: False')\n",
    "    # Resume training\n",
    "    parser.add_argument('--args_path', default=None, help='Checkpoint args json path. default: None')\n",
    "    parser.add_argument('--gen_ckpt_path', '-gcp', default=None,\n",
    "                        help='Generator and optimizer checkpoint path. default: None')\n",
    "    parser.add_argument('--dis_ckpt_path', '-dcp', default=None,\n",
    "                        help='Discriminator and optimizer checkpoint path. default: None')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def sample_from_data(args, device, data_loader):\n",
    "    real, y = next(data_loader)\n",
    "    if real.size(0) < args.batch_size:\n",
    "        real, y = next(data_loader)\n",
    "    real, y = real.to(device), y.to(device)\n",
    "    if not args.cGAN:\n",
    "        y = None\n",
    "    return real, y\n",
    "\n",
    "\n",
    "def sample_from_gen(args, device, num_classes, gen):\n",
    "    z = utils.sample_z(\n",
    "        args.batch_size, args.gen_dim_z, device, args.gen_distribution\n",
    "    )\n",
    "    if args.cGAN:\n",
    "        pseudo_y = utils.sample_pseudo_labels(\n",
    "            num_classes, args.batch_size, device\n",
    "        )\n",
    "    else:\n",
    "        pseudo_y = None\n",
    "\n",
    "    fake = gen(z, pseudo_y)\n",
    "    return fake, pseudo_y, z\n",
    "\n",
    "\n",
    "def pick_fixed_img(args, train_loader, img_num):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for i in range(8):\n",
    "        x_data, y_data = sample_from_data(args, dev, train_loader)\n",
    "        for j in range(x_data.size(0)):\n",
    "            img_list.append(x_data[j])\n",
    "            label_list.append(y_data[j])\n",
    "\n",
    "    img_list = img_list[0: img_num]\n",
    "    label_list = label_list[0: img_num]\n",
    "\n",
    "    return img_list, label_list\n",
    "\n",
    "\n",
    "def directory_path(args):\n",
    "    output = \"output\"\n",
    "    weight_path = os.path.join(output, args.exp_version, 'weight')\n",
    "    img_path = os.path.join(output, args.exp_version, 'img')\n",
    "    loss_path = os.path.join(output, args.exp_version, 'loss')\n",
    "\n",
    "    if os.path.exists(weight_path) is False:\n",
    "        os.makedirs(weight_path)\n",
    "    if os.path.exists(img_path) is False:\n",
    "        os.makedirs(img_path)\n",
    "    if os.path.exists(loss_path) is False:\n",
    "        os.makedirs(loss_path)\n",
    "\n",
    "    return weight_path, img_path, loss_path\n",
    "\n",
    "\n",
    "def data_loader(args):\n",
    "    root_path = args.dataset_root\n",
    "    data_root = os.path.join(root_path, args.dataset)\n",
    "    print(data_root)\n",
    "    if args.dataset == \"omniglot\":\n",
    "        train_loader, s_dlen = img_dataloder(\n",
    "            args=args,\n",
    "            root=data_root\n",
    "        )\n",
    "        print(\"omniglot data_loader\")\n",
    "        num_classes = 1623\n",
    "    elif args.dataset == \"vgg\" or \"cub\":\n",
    "        train_loader, s_dlen = img_dataloder(\n",
    "            args=args,\n",
    "            root=data_root\n",
    "        )\n",
    "        print(\"vgg data_loader\")\n",
    "        if args.dataset == \"vgg\":\n",
    "            num_classes = 2300\n",
    "        elif args.dataset == \"cub\":\n",
    "            num_classes = 200\n",
    "    elif args.dataset == \"animal\":\n",
    "        train_loader, s_dlen = img_dataloder(\n",
    "            args=args,\n",
    "            root=data_root\n",
    "        )\n",
    "        print(\"animal data_loader\")\n",
    "        num_classes = 147\n",
    "    elif args.dataset == \"celeba\":\n",
    "        root_path = args.dataset_root\n",
    "        data_root = os.path.join(root_path, args.dataset)\n",
    "        print(data_root)\n",
    "        train_loader, s_dlen, num_classes = celeba_data_loader(\n",
    "            root=data_root,\n",
    "            batch_size=64)\n",
    "    else:\n",
    "        raise Exception(\"Enter omniglot or vgg or animal or celeba\")\n",
    "\n",
    "    train_loader = iter(utils.cycle(train_loader))\n",
    "    return train_loader, s_dlen, num_classes\n",
    "\n",
    "\n",
    "def select_model(args, _n_cls):\n",
    "    print(\"selecting model\")\n",
    "    if args.dataset == \"omniglot\":\n",
    "        gen = Omniglot_Generator(\n",
    "            args.gen_num_features, args.gen_dim_z, bottom_width=7, activation=F.relu,\n",
    "            num_classes=_n_cls, distribution=args.gen_distribution).to(dev)\n",
    "        dis = Omniglot_Discriminator(args.dis_num_features, _n_cls, F.relu).to(dev)\n",
    "    elif args.dataset == \"vgg\" or \"cub\":\n",
    "        gen = VGG_Generator(\n",
    "            args.gen_num_features * 2, args.gen_dim_z, bottom_width=4, activation=F.relu,\n",
    "            num_classes=_n_cls, distribution=args.gen_distribution).to(dev)\n",
    "        dis = VGG_Discriminator(args.gen_num_features * 2, _n_cls, F.relu).to(dev)\n",
    "    elif args.dataset == \"celeba\":\n",
    "        gen = VGG_Generator(\n",
    "            args.gen_num_features * 2, args.gen_dim_z, bottom_width=4, activation=F.relu,\n",
    "            num_classes=_n_cls, distribution=args.gen_distribution).to(dev)\n",
    "        dis = VGG_Discriminator(args.gen_num_features * 2, _n_cls, F.relu).to(dev)\n",
    "    elif args.dataset == \"animal\":\n",
    "        gen = Animal_Generator(\n",
    "            args.gen_num_features * 2, args.gen_dim_z, bottom_width=4, activation=F.relu,\n",
    "            num_classes=_n_cls, distribution=args.gen_distribution).to(dev)\n",
    "        dis = Animal_Discriminator(args.gen_num_features * 2, _n_cls, F.relu).to(dev)\n",
    "    else:\n",
    "        raise Exception(\"Enter model omniglot or vgg or animal\")\n",
    "\n",
    "    return gen, dis\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = get_args()\n",
    "    weight_path, img_path, loss_path = directory_path(args)\n",
    "    writer = SummaryWriter(loss_path)\n",
    "\n",
    "    # CUDA setting\n",
    "    if not torch.cuda.is_available():\n",
    "        raise ValueError(\"Should buy GPU!\")\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # dataloading\n",
    "    train_loader, s_dlen, _n_cls = data_loader(args)\n",
    "\n",
    "    fixed_z = torch.randn(500, 10, 128)\n",
    "    fixed_img_list, fixed_label_list = pick_fixed_img(args, train_loader, 500)\n",
    "    \n",
    "    fixed_img_list2 = []\n",
    "    fixed_label_list2 = []\n",
    "    for i in range(len(fixed_label_list)):\n",
    "        if fixed_label_list[i].item() != _n_cls:\n",
    "            fixed_label_list2.append(fixed_label_list[i])\n",
    "            fixed_img_list2.append(fixed_img_list[i])\n",
    "    \n",
    "    # initialize model\n",
    "    gen, dis = select_model(args, _n_cls)\n",
    "\n",
    "    opt_gen = optim.Adam(gen.parameters(), args.lr, (args.beta1, args.beta2))\n",
    "    opt_dis = optim.Adam(dis.parameters(), args.lr, (args.beta1, args.beta2))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    bs = args.batch_size\n",
    "    # Training loop\n",
    "    for n_iter in tqdm.tqdm(range(0, args.max_iteration)):\n",
    "\n",
    "        if n_iter >= args.lr_decay_start:\n",
    "            decay_lr(opt_gen, args.max_iteration, args.lr_decay_start, args.lr)\n",
    "            decay_lr(opt_dis, args.max_iteration, args.lr_decay_start, args.lr)\n",
    "\n",
    "        # ==================== Beginning of 1 iteration. ====================\n",
    "        _l_g = .0\n",
    "        cumulative_loss_dis = .0\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        opt_dis.zero_grad()\n",
    "\n",
    "        real_images, real_y = sample_from_data(args, dev, train_loader)\n",
    "        fake_images, pseudo_y, _ = sample_from_gen(args, dev, _n_cls, gen)\n",
    "\n",
    "        real_y = real_y.cuda()\n",
    "        pseudo_y = pseudo_y.cuda()\n",
    "\n",
    "        real_labels = torch.FloatTensor(real_y.size(0), _n_cls+1).cuda()\n",
    "        fake_labels = torch.FloatTensor(real_y.size(0), _n_cls+1).cuda()\n",
    "\n",
    "        real_labels.zero_()\n",
    "        fake_labels.zero_()\n",
    "\n",
    "        real_labels.scatter_(1, real_y.unsqueeze(1), 1)\n",
    "        fake_labels.scatter_(1, pseudo_y.unsqueeze(1), 1)\n",
    "\n",
    "        rotated_bs = bs // 2\n",
    "        num_rot_examples = rotated_bs // NUM_ROTATIONS\n",
    "\n",
    "        all_features, all_labels = utils.merge_with_rotation_data(\n",
    "            real_images, fake_images, real_labels[:, :_n_cls], fake_labels[:, :_n_cls], num_rot_examples)\n",
    "\n",
    "        \"\"\"============================= Discriminator Forward =============================\"\"\"\n",
    "\n",
    "        d_predictions_d, d_logits_d, rot_logits_d, aux_logits_d, is_label_available_d = dis. \\\n",
    "            discriminator_with_additonal_heads(x=all_features.detach(), y=all_labels.detach())\n",
    "\n",
    "        expected_batch_size = 2 * bs\n",
    "        expected_batch_size += 2 * (NUM_ROTATIONS - 1) * num_rot_examples\n",
    "\n",
    "        if d_logits_d.shape[0] != expected_batch_size:\n",
    "            raise ValueError(\"Batch size unexpected: got %r expected %r\" % (\n",
    "                d_logits_d.shape[0], expected_batch_size))\n",
    "\n",
    "        prob_real_d, prob_fake_d = torch.chunk(d_predictions_d, 2, dim=0)\n",
    "        prob_real_d, prob_fake_d = prob_real_d[:bs], prob_fake_d[:bs]\n",
    "\n",
    "        logits_real_d, logits_fake_d = torch.chunk(d_logits_d, 2, dim=0)\n",
    "        logits_real_d, logits_fake_d = logits_real_d[:bs], logits_fake_d[:bs]\n",
    "\n",
    "        d_loss, _, _, _ = losses.hinge_losses(\n",
    "            d_real=prob_real_d, d_fake=prob_fake_d,\n",
    "            d_real_logits=logits_real_d, d_fake_logits=logits_fake_d)\n",
    "        \n",
    "        \n",
    "        rot_real_logits, _ = torch.chunk(rot_logits_d, 2, dim=0)\n",
    "        rot_real_logits = rot_real_logits[-rotated_bs:]\n",
    "\n",
    "        labels_rotated = torch.tensor(list(range(NUM_ROTATIONS))).repeat(num_rot_examples)\n",
    "        real_loss = criterion(rot_real_logits, labels_rotated)\n",
    "        d_loss += real_loss * 1.0\n",
    "\n",
    "        real_aux_logits, _ = torch.chunk(aux_logits_d, 2, dim=0)\n",
    "        real_aux_logits = real_aux_logits[:bs]\n",
    "\n",
    "        is_label_available, _ = torch.chunk(is_label_available_d, 2, dim=0)\n",
    "        is_label_available = is_label_available.squeeze(1)[:bs].unsqueeze(1)\n",
    "\n",
    "        class_loss_real = losses.weighted_cross_entropy(\n",
    "            real_labels[:, :_n_cls], real_aux_logits, weights=is_label_available)\n",
    "        \n",
    "        d_loss += class_loss_real * 1.0\n",
    "        \n",
    "        opt_gen.zero_grad()\n",
    "        opt_dis.zero_grad()\n",
    "        d_loss.backward()\n",
    "        opt_dis.step()\n",
    "        \n",
    "        \"\"\"=============================== Generator Forward =============================\"\"\"\n",
    "        \n",
    "        fake_images, pseudo_y, _ = sample_from_gen(args, dev, _n_cls, gen)\n",
    "        pseudo_y = pseudo_y.cuda()\n",
    "\n",
    "        fake_labels = torch.FloatTensor(real_y.size(0), _n_cls+1).cuda()\n",
    "        fake_labels.zero_()\n",
    "        fake_labels.scatter_(1, pseudo_y.unsqueeze(1), 1)\n",
    "\n",
    "        rotated_bs = bs // 2\n",
    "        num_rot_examples = rotated_bs // NUM_ROTATIONS\n",
    "\n",
    "        all_features, all_labels = utils.merge_with_rotation_data(\n",
    "            real_images, fake_images, real_labels[:, :_n_cls], fake_labels[:, :_n_cls], num_rot_examples)\n",
    "        \n",
    "        d_predictions, d_logits, rot_logits, aux_logits, is_label_available = \\\n",
    "            dis.discriminator_with_additonal_heads(x=all_features, y=all_labels)\n",
    "\n",
    "        if d_logits.shape[0] != expected_batch_size:\n",
    "            raise ValueError(\"Batch size unexpected: got %r expected %r\" % (\n",
    "                d_logits.shape[0], expected_batch_size))\n",
    "\n",
    "        prob_real, prob_fake = torch.chunk(d_predictions, 2, dim=0)\n",
    "        prob_real, prob_fake = prob_real[:bs], prob_fake[:bs]\n",
    "\n",
    "        logits_real, logits_fake = torch.chunk(d_logits, 2, dim=0)\n",
    "        logits_real, logits_fake = logits_real[:bs], logits_fake[:bs]\n",
    "\n",
    "        _, _, _, g_loss = losses.hinge_losses(\n",
    "            d_real=prob_real, d_fake=prob_fake,\n",
    "            d_real_logits=logits_real, d_fake_logits=logits_fake)\n",
    "\n",
    "        _, rot_fake_logits = torch.chunk(rot_logits, 2, dim=0)\n",
    "        rot_fake_logits = rot_fake_logits[-rotated_bs:]\n",
    "\n",
    "        labels_rotated = torch.tensor(list(range(NUM_ROTATIONS))).repeat(num_rot_examples)\n",
    "        fake_loss = criterion(rot_fake_logits, labels_rotated)\n",
    "\n",
    "        g_loss += fake_loss * 0.2\n",
    "        \n",
    "        rot_real_pred = torch.argmax(rot_real_logits, dim=1, keepdim=True)\n",
    "        rot_fake_pred = torch.argmax(rot_fake_logits, dim=1, keepdim=True)\n",
    "\n",
    "        accuracy_real = (labels_rotated == rot_real_pred).sum().item() / rot_real_pred.size(0)\n",
    "        accuracy_fake = (labels_rotated == rot_fake_pred).sum().item() / rot_fake_pred.size(0)\n",
    "        \n",
    "        opt_gen.zero_grad()\n",
    "        opt_dis.zero_grad()\n",
    "        g_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        writer.add_scalar('loss/total_G_loss', g_loss.item(), n_iter)\n",
    "        writer.add_scalar('loss/total_D_loss', d_loss.item(), n_iter)\n",
    "        writer.add_scalar('loss/real_loss', real_loss.item(), n_iter)\n",
    "        writer.add_scalar('loss/fake_loss', fake_loss.item(), n_iter)\n",
    "        writer.add_scalar('loss/G_loss', g_loss.item() - fake_loss.item(), n_iter)\n",
    "        writer.add_scalar('loss/D_loss', d_loss.item() - real_loss.item() -\n",
    "                          class_loss_real.item(), n_iter)\n",
    "\n",
    "        writer.add_scalar('accuracy/real', accuracy_real, n_iter)\n",
    "        writer.add_scalar('accuracy/fake', accuracy_fake, n_iter)\n",
    "        writer.add_scalar(\"loss/class_loss_real\", class_loss_real)\n",
    "        writer.add_scalar(\"label_frac\", torch.mean(is_label_available))\n",
    "\n",
    "        # ==================== End of 1 iteration. ====================\n",
    "\n",
    "        if n_iter % args.log_interval == 0:\n",
    "            tqdm.tqdm.write(\n",
    "                'iteration: {:07d}/{:07d}, loss gen: {:05f}, loss dis {:05f}'.format(\n",
    "                    n_iter, args.max_iteration, g_loss.item(), d_loss.item()))\n",
    "\n",
    "        if n_iter % args.checkpoint_interval == 0:\n",
    "            #Save checkpoints!\n",
    "            utils.save_checkpoints(args, n_iter, gen, opt_gen, dis, opt_dis, weight_path)\n",
    "            utils.save_img(fixed_img_list2, fixed_label_list2, fixed_z, gen,\n",
    "                           32, 28, img_path, n_iter, device=dev)\n",
    "    if args.test:\n",
    "        shutil.rmtree(args.results_root)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
