{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training script for tiny-imagenet.\n",
    "# Again, this script has a lot of bugs everywhere.\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import losses\n",
    "\n",
    "from models.discriminators.snresnet64 import Omniglot_Discriminator, VGG_Discriminator\n",
    "from models.generators.resnet64 import Omniglot_Generator, VGG_Generator\n",
    "\n",
    "from dataloader import omniglot_data_loader, vgg_data_loader, img_dataloder\n",
    "import utils\n",
    "from torch.nn.utils import spectral_norm\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_ROTATIONS = 4\n",
    "\n",
    "# Copied from https://github.com/naoto0804/pytorch-AdaIN/blob/master/sampler.py#L5-L15\n",
    "def InfiniteSampler(n):\n",
    "    # i = 0\n",
    "    i = n - 1\n",
    "    order = np.random.permutation(n)\n",
    "    while True:\n",
    "        yield order[i]\n",
    "        i += 1\n",
    "        if i >= n:\n",
    "            np.random.seed()\n",
    "            order = np.random.permutation(n)\n",
    "            i = 0\n",
    "\n",
    "\n",
    "# Copied from https://github.com/naoto0804/pytorch-AdaIN/blob/master/sampler.py#L18-L26\n",
    "class InfiniteSamplerWrapper(data.sampler.Sampler):\n",
    "    def __init__(self, data_source):\n",
    "        self.num_samples = len(data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(InfiniteSampler(self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return 2 ** 31\n",
    "\n",
    "\n",
    "def decay_lr(opt, max_iter, start_iter, initial_lr):\n",
    "    \"\"\"Decay learning rate linearly till 0.\"\"\"\n",
    "    coeff = -initial_lr / (max_iter - start_iter)\n",
    "    for pg in opt.param_groups:\n",
    "        pg['lr'] += coeff\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--exp_version\", type=str, default=\"3-shot_vgg_0.0002\")\n",
    "    parser.add_argument('--dataset', type=str, default=\"vgg\", help=\"omniglot or vgg\")\n",
    "    parser.add_argument('--dataset_root', type=str, default=\"/home/userB/yonggyukim/data\")\n",
    "    parser.add_argument('--n_shot', type=str, default=\"3-shot\")\n",
    "\n",
    "    parser.add_argument('--lr', type=float, default=0.0002,\n",
    "                        help='Initial learning rate of Adam. default: 0.0002')\n",
    "    parser.add_argument('--lr_decay_start', '-lds', type=int, default=50000,\n",
    "                        help='Start point of learning rate decay. default: 50000')\n",
    "\n",
    "    # Dataset configuration\n",
    "    parser.add_argument('--cGAN', default=True, action='store_true',\n",
    "                        help='to train cGAN, set this ``True``. default: False')\n",
    "    parser.add_argument('--data_root', type=str, default='tiny-imagenet-200',\n",
    "                        help='path to dataset root directory. default: tiny-imagenet-200')\n",
    "    parser.add_argument('--batch_size', '-B', type=int, default=64,\n",
    "                        help='mini-batch size of training data. default: 64')\n",
    "    parser.add_argument('--eval_batch_size', '-eB', default=None,\n",
    "                        help='mini-batch size of evaluation data. default: None')\n",
    "    parser.add_argument('--num_workers', type=int, default=8,\n",
    "                        help='Number of workers for training data loader. default: 8')\n",
    "    # Generator configuration\n",
    "    parser.add_argument('--gen_num_features', '-gnf', type=int, default=32,\n",
    "                        help='Number of features of generator (a.k.a. nplanes or ngf). default: 64')\n",
    "    parser.add_argument('--gen_dim_z', '-gdz', type=int, default=128,\n",
    "                        help='Dimension of generator input noise. default: 128')\n",
    "    parser.add_argument('--gen_bottom_width', '-gbw', type=int, default=7,\n",
    "                        help='Initial size of hidden variable of generator. default: 4')\n",
    "    parser.add_argument('--gen_distribution', '-gd', type=str, default='normal',\n",
    "                        help='Input noise distribution: normal (default) or uniform.')\n",
    "    # Discriminator (Critic) configuration\n",
    "    parser.add_argument('--dis_arch_concat', '-concat', default=False, action='store_true',\n",
    "                        help='If use concat discriminator, set this true. default: False')\n",
    "    parser.add_argument('--dis_emb', type=int, default=128,\n",
    "                        help='Parameter for concat discriminator. default: 128')\n",
    "    parser.add_argument('--dis_num_features', '-dnf', type=int, default=32,\n",
    "                        help='Number of features of discriminator (a.k.a nplanes or ndf). default: 64')\n",
    "    # Optimizer settings\n",
    "    parser.add_argument('--beta1', type=float, default=0.0,\n",
    "                        help='beta1 (betas[0]) value of Adam. default: 0.0')\n",
    "    parser.add_argument('--beta2', type=float, default=0.9,\n",
    "                        help='beta2 (betas[1]) value of Adam. default: 0.9')\n",
    "    # Training setting\n",
    "    parser.add_argument('--seed', type=int, default=46,\n",
    "                        help='Random seed. default: 46 (derived from Nogizaka46)')\n",
    "    parser.add_argument('--max_iteration', '-N', type=int, default=100000,\n",
    "                        help='Max iteration number of training. default: 100000')\n",
    "    parser.add_argument('--n_dis', type=int, default=5,\n",
    "                        help='Number of discriminator updater per generator updater. default: 5')\n",
    "    parser.add_argument('--num_classes', '-nc', type=int, default=0,\n",
    "                        help='Number of classes in training data. No need to set. default: 0')\n",
    "    parser.add_argument('--loss_type', type=str, default='hinge',\n",
    "                        help='loss function name. hinge (default) or dcgan.')\n",
    "    parser.add_argument('--relativistic_loss', '-relloss', default=False, action='store_true',\n",
    "                        help='Apply relativistic loss or not. default: False')\n",
    "    parser.add_argument('--calc_FID', default=False, action='store_true',\n",
    "                        help='If calculate FID score, set this ``True``. default: False')\n",
    "    # Log and Save interval configuration\n",
    "    parser.add_argument('--results_root', type=str, default='results',\n",
    "                        help='Path to results directory. default: results')\n",
    "    parser.add_argument('--no_tensorboard', action='store_true', default=False,\n",
    "                        help='If you dislike tensorboard, set this ``False``. default: True')\n",
    "    parser.add_argument('--no_image', action='store_true', default=False,\n",
    "                        help='If you dislike saving images on tensorboard, set this ``True``. default: False')\n",
    "    parser.add_argument('--checkpoint_interval', '-ci', type=int, default=1000,\n",
    "                        help='Interval of saving checkpoints (model and optimizer). default: 1000')\n",
    "    parser.add_argument('--log_interval', '-li', type=int, default=100,\n",
    "                        help='Interval of showing losses. default: 100')\n",
    "    parser.add_argument('--eval_interval', '-ei', type=int, default=100,\n",
    "                        help='Interval for evaluation (save images and FID calculation). default: 1000')\n",
    "    parser.add_argument('--n_eval_batches', '-neb', type=int, default=100,\n",
    "                        help='Number of mini-batches used in evaluation. default: 100')\n",
    "    parser.add_argument('--n_fid_images', '-nfi', type=int, default=50,\n",
    "                        help='Number of images to calculate FID. default: 5000')\n",
    "    parser.add_argument('--test', default=False, action='store_true',\n",
    "                        help='If test this python program, set this ``True``. default: False')\n",
    "    # Resume training\n",
    "    parser.add_argument('--args_path', default=None, help='Checkpoint args json path. default: None')\n",
    "    parser.add_argument('--gen_ckpt_path', '-gcp', default=None,\n",
    "                        help='Generator and optimizer checkpoint path. default: None')\n",
    "    parser.add_argument('--dis_ckpt_path', '-dcp', default=None,\n",
    "                        help='Discriminator and optimizer checkpoint path. default: None')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def sample_from_data(args, device, data_loader):\n",
    "    real, y = next(data_loader)\n",
    "    if real.size(0) < args.batch_size:\n",
    "        real, y = next(data_loader)\n",
    "    real, y = real.to(device), y.to(device)\n",
    "    if not args.cGAN:\n",
    "        y = None\n",
    "    return real, y\n",
    "\n",
    "\n",
    "def sample_from_gen(args, device, num_classes, gen):\n",
    "    z = utils.sample_z(\n",
    "        args.batch_size, args.gen_dim_z, device, args.gen_distribution\n",
    "    )\n",
    "    if args.cGAN:\n",
    "        pseudo_y = utils.sample_pseudo_labels(\n",
    "            num_classes, args.batch_size, device\n",
    "        )\n",
    "    else:\n",
    "        pseudo_y = None\n",
    "\n",
    "    fake = gen(z, pseudo_y)\n",
    "    return fake, pseudo_y, z\n",
    "\n",
    "\n",
    "def pick_fixed_img(args, train_loader, img_num):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for i in range(7):\n",
    "        x_data, y_data = sample_from_data(args, dev, train_loader)\n",
    "        for j in range(x_data.size(0)):\n",
    "            img_list.append(x_data[j])\n",
    "            label_list.append(y_data[j])\n",
    "\n",
    "    img_list = img_list[0: img_num]\n",
    "    label_list = label_list[0: img_num]\n",
    "\n",
    "    return img_list, label_list\n",
    "\n",
    "\n",
    "def directory_path(args):\n",
    "    output = \"output\"\n",
    "    weight_path = os.path.join(output, args.exp_version, 'weight')\n",
    "    img_path = os.path.join(output, args.exp_version, 'img')\n",
    "    loss_path = os.path.join(output, args.exp_version, 'loss')\n",
    "\n",
    "    if os.path.exists(weight_path) is False:\n",
    "        os.makedirs(weight_path)\n",
    "    if os.path.exists(img_path) is False:\n",
    "        os.makedirs(img_path)\n",
    "    if os.path.exists(loss_path) is False:\n",
    "        os.makedirs(loss_path)\n",
    "\n",
    "    return weight_path, img_path, loss_path\n",
    "\n",
    "\n",
    "def data_loader(args):\n",
    "    root_path = args.dataset_root\n",
    "    data_root = os.path.join(root_path, args.dataset)\n",
    "    print(data_root)\n",
    "    if args.dataset == \"omniglot\":\n",
    "        train_loader, s_dlen = img_dataloder(\n",
    "            args=args,\n",
    "            root=data_root\n",
    "        )\n",
    "        print(\"omniglot data_loader\")\n",
    "        num_classes = 1623\n",
    "    elif args.dataset == \"vgg\":\n",
    "        train_loader, s_dlen = img_dataloder(\n",
    "            args=args,\n",
    "            root=data_root\n",
    "        )\n",
    "        print(\"vgg data_loader\")\n",
    "        num_classes = 2300\n",
    "    elif args.dataset == \"vgg\":\n",
    "        pass\n",
    "    elif args.dataset == \"animal\":\n",
    "        pass\n",
    "    elif args.dataset == \"celeba\":\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception(\"Enter omniglot or vgg\")\n",
    "\n",
    "    train_loader = iter(utils.cycle(train_loader))\n",
    "    return train_loader, s_dlen, num_classes\n",
    "\n",
    "\n",
    "def select_model(args, _n_cls):\n",
    "    print(\"selecting model\")\n",
    "    if args.dataset == \"omniglot\":\n",
    "        gen = Omniglot_Generator(\n",
    "            args.gen_num_features, args.gen_dim_z, bottom_width=7, activation=F.relu,\n",
    "            num_classes=_n_cls, distribution=args.gen_distribution).to(dev)\n",
    "        dis = Omniglot_Discriminator(args.dis_num_features, _n_cls, F.relu).to(dev)\n",
    "    elif args.dataset == \"vgg\":\n",
    "        gen = VGG_Generator(\n",
    "            args.gen_num_features * 2, args.gen_dim_z, bottom_width=4, activation=F.relu,\n",
    "            num_classes=_n_cls, distribution=args.gen_distribution).to(dev)\n",
    "        dis = VGG_Discriminator(args.gen_num_features * 2, _n_cls, F.relu).to(dev)\n",
    "    else:\n",
    "        raise Exception(\"Enter model omniglot or vgg\")\n",
    "\n",
    "    return gen, dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/userB/yonggyukim/data/vgg\n",
      "vgg data_loader\n"
     ]
    }
   ],
   "source": [
    "    args = get_args()\n",
    "    weight_path, img_path, loss_path = directory_path(args)\n",
    "    writer = SummaryWriter(loss_path)\n",
    "\n",
    "    # CUDA setting\n",
    "    if not torch.cuda.is_available():\n",
    "        raise ValueError(\"Should buy GPU!\")\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # dataloading\n",
    "    train_loader, s_dlen, _n_cls = data_loader(args)\n",
    "\n",
    "    fixed_z = torch.randn(400, 10, 128)\n",
    "    fixed_img_list, fixed_label_list = pick_fixed_img(args, train_loader, 400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting model\n"
     ]
    }
   ],
   "source": [
    "    # initialize model\n",
    "    gen, dis = select_model(args, _n_cls)\n",
    "\n",
    "    opt_gen = optim.Adam(gen.parameters(), args.lr, (args.beta1, args.beta2))\n",
    "    opt_dis = optim.Adam(dis.parameters(), args.lr, (args.beta1, args.beta2))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    bs = args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if n_iter >= args.lr_decay_start:\n",
    "            decay_lr(opt_gen, args.max_iteration, args.lr_decay_start, args.lr)\n",
    "            decay_lr(opt_dis, args.max_iteration, args.lr_decay_start, args.lr)\n",
    "\n",
    "        # ==================== Beginning of 1 iteration. ====================\n",
    "        _l_g = .0\n",
    "        cumulative_loss_dis = .0\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        opt_dis.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images, real_y = sample_from_data(args, dev, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yonggyu/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "fake_images, pseudo_y, _ = sample_from_gen(args, dev, _n_cls, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 64, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 64, 64])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2300, 2300, 2300, 2300, 2300, 2300, 2300, 2300, 2300, 2300, 1308, 2300,\n",
       "        2300, 2300, 2300, 2300, 2300, 2300,  711, 2300, 2300, 1521, 2300, 2300,\n",
       "        2300, 2300, 1491, 2300, 2300, 2300, 2300, 2300, 2300, 2300, 2300, 2300,\n",
       "        1591, 2300, 2300, 2300, 2300, 2300, 2300, 2300, 2300, 2300, 2300, 2300,\n",
       "        2300, 2300, 2300, 1545, 2300, 2300, 2300, 2300, 2300, 2300, 2300, 2300,\n",
       "        2300, 2300, 2300, 2300])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2300"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_n_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_y = real_y.cuda()\n",
    "pseudo_y = pseudo_y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels = torch.FloatTensor(real_y.size(0), _n_cls+1).cuda()\n",
    "fake_labels = torch.FloatTensor(real_y.size(0), _n_cls+1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels.zero_()\n",
    "fake_labels.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "        real_labels.scatter_(1, real_y.unsqueeze(1), 1)\n",
    "        fake_labels.scatter_(1, pseudo_y.unsqueeze(1), 1)\n",
    "\n",
    "        rotated_bs = bs // 2\n",
    "        num_rot_examples = rotated_bs // NUM_ROTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "        all_features, all_labels = utils.merge_with_rotation_data(\n",
    "            real_images, fake_images, real_labels[:, :_n_cls], fake_labels[:, :_n_cls], num_rot_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([176, 1])\n",
      "torch.Size([176, 2300])\n",
      "torch.Size([176, 2300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yonggyu/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "d_predictions_d, d_logits_d, rot_logits_d, aux_logits_d, is_label_available_d = dis. \\\n",
    "discriminator_with_additonal_heads(x=all_features.detach(), y=all_labels.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "        expected_batch_size = 2 * bs\n",
    "        expected_batch_size += 2 * (NUM_ROTATIONS - 1) * num_rot_examples\n",
    "\n",
    "        if d_logits_d.shape[0] != expected_batch_size:\n",
    "            raise ValueError(\"Batch size unexpected: got %r expected %r\" % (\n",
    "                d_logits_d.shape[0], expected_batch_size))\n",
    "\n",
    "        prob_real_d, prob_fake_d = torch.chunk(d_predictions_d, 2, dim=0)\n",
    "        prob_real_d, prob_fake_d = prob_real_d[:bs], prob_fake_d[:bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "        logits_real_d, logits_fake_d = torch.chunk(d_logits_d, 2, dim=0)\n",
    "        logits_real_d, logits_fake_d = logits_real_d[:bs], logits_fake_d[:bs]\n",
    "\n",
    "        d_loss, _, _, _ = losses.hinge_losses(\n",
    "            d_real=prob_real_d, d_fake=prob_fake_d,\n",
    "            d_real_logits=logits_real_d, d_fake_logits=logits_fake_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([176, 1])\n",
      "torch.Size([176, 2300])\n",
      "torch.Size([176, 2300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yonggyu/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "        \"\"\"=============================== Generator Forward =============================\"\"\"\n",
    "\n",
    "        d_predictions, d_logits, rot_logits, aux_logits, is_label_available = \\\n",
    "            dis.discriminator_with_additonal_heads(x=all_features, y=all_labels)\n",
    "\n",
    "        if d_logits.shape[0] != expected_batch_size:\n",
    "            raise ValueError(\"Batch size unexpected: got %r expected %r\" % (\n",
    "                d_logits.shape[0], expected_batch_size))\n",
    "\n",
    "        prob_real, prob_fake = torch.chunk(d_predictions, 2, dim=0)\n",
    "        prob_real, prob_fake = prob_real[:bs], prob_fake[:bs]\n",
    "\n",
    "        logits_real, logits_fake = torch.chunk(d_logits, 2, dim=0)\n",
    "        logits_real, logits_fake = logits_real[:bs], logits_fake[:bs]\n",
    "\n",
    "        _, _, _, g_loss = losses.hinge_losses(\n",
    "            d_real=prob_real, d_fake=prob_fake,\n",
    "            d_real_logits=logits_real, d_fake_logits=logits_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "        rot_real_logits, rot_fake_logits = torch.chunk(rot_logits, 2, dim=0)\n",
    "        rot_real_logits = rot_real_logits[-rotated_bs:]\n",
    "        rot_fake_logits = rot_fake_logits[-rotated_bs:]\n",
    "\n",
    "        labels_rotated = torch.tensor(list(range(NUM_ROTATIONS))).repeat(num_rot_examples)\n",
    "\n",
    "        fake_loss = criterion(rot_fake_logits, labels_rotated)\n",
    "        real_loss = criterion(rot_real_logits, labels_rotated)\n",
    "\n",
    "        d_loss += real_loss * 1.0\n",
    "\n",
    "        rot_real_pred = torch.argmax(rot_real_logits, dim=1, keepdim=True)\n",
    "        rot_fake_pred = torch.argmax(rot_fake_logits, dim=1, keepdim=True)\n",
    "\n",
    "        accuracy_real = (labels_rotated == rot_real_pred).sum().item() / rot_real_pred.size(0)\n",
    "        accuracy_fake = (labels_rotated == rot_fake_pred).sum().item() / rot_fake_pred.size(0)\n",
    "\n",
    "        real_aux_logits, _ = torch.chunk(aux_logits, 2, dim=0)\n",
    "        real_aux_logits = real_aux_logits[:bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "        is_label_available, _ = torch.chunk(is_label_available, 2, dim=0)\n",
    "        is_label_available = is_label_available.squeeze(1)[:bs].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2300])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels[:, :_n_cls].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2300])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_aux_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_label_available.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        class_loss_real = losses.weighted_cross_entropy(\n",
    "            real_labels[:, :_n_cls], real_aux_logits, weights=is_label_available)\n",
    "\n",
    "        d_loss += class_loss_real * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "        d_loss.backward(retain_graph=True)\n",
    "        opt_dis.step()\n",
    "\n",
    "        g_loss += fake_loss * 0.2\n",
    "        g_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0903, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6847, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(83),\n",
       " tensor(1343),\n",
       " tensor(308),\n",
       " tensor(938),\n",
       " tensor(1167),\n",
       " tensor(1170),\n",
       " tensor(1970),\n",
       " tensor(322),\n",
       " tensor(691),\n",
       " tensor(1749),\n",
       " tensor(1519),\n",
       " tensor(1225),\n",
       " tensor(529),\n",
       " tensor(1094),\n",
       " tensor(252),\n",
       " tensor(1794),\n",
       " tensor(962),\n",
       " tensor(2253),\n",
       " tensor(755),\n",
       " tensor(423),\n",
       " tensor(83),\n",
       " tensor(541),\n",
       " tensor(1355),\n",
       " tensor(548),\n",
       " tensor(444),\n",
       " tensor(1493),\n",
       " tensor(921),\n",
       " tensor(684),\n",
       " tensor(704),\n",
       " tensor(795),\n",
       " tensor(82),\n",
       " tensor(2084),\n",
       " tensor(1607),\n",
       " tensor(2253),\n",
       " tensor(1778),\n",
       " tensor(1378),\n",
       " tensor(1588),\n",
       " tensor(645),\n",
       " tensor(1227),\n",
       " tensor(2254),\n",
       " tensor(1965),\n",
       " tensor(1424),\n",
       " tensor(1215),\n",
       " tensor(1680)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_img_list2 = []\n",
    "fixed_label_list2 = []\n",
    "for i in range(len(fixed_label_list)):\n",
    "    if fixed_label_list[i].item() != _n_cls:\n",
    "        fixed_label_list2.append(fixed_label_list[i])\n",
    "        fixed_img_list2.append(fixed_img_list[i])\n",
    "        \n",
    "fixed_label_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  5,  12,  24,  35,  56,  63,  66,  71,  81,  92,  94,  95, 105, 112,\n",
       "        113, 130, 131, 132, 144, 169, 172, 188, 203, 217, 219, 221, 257, 266,\n",
       "        269, 272, 276, 282, 287, 293, 303, 310, 311, 315, 338, 358, 369, 378,\n",
       "        387, 392])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        rot_real_logits, rot_fake_logits = torch.chunk(rot_logits, 2, dim=0)\n",
    "        rot_real_logits = rot_real_logits[-rotated_bs:]\n",
    "        rot_fake_logits = rot_fake_logits[-rotated_bs:]\n",
    "\n",
    "        labels_rotated = torch.tensor(list(range(NUM_ROTATIONS))).repeat(num_rot_examples)\n",
    "\n",
    "        fake_loss = criterion(rot_fake_logits, labels_rotated)\n",
    "        real_loss = criterion(rot_real_logits, labels_rotated)\n",
    "\n",
    "        d_loss += real_loss * 1.0\n",
    "\n",
    "        rot_real_pred = torch.argmax(rot_real_logits, dim=1, keepdim=True)\n",
    "        rot_fake_pred = torch.argmax(rot_fake_logits, dim=1, keepdim=True)\n",
    "\n",
    "        accuracy_real = (labels_rotated == rot_real_pred).sum().item() / rot_real_pred.size(0)\n",
    "        accuracy_fake = (labels_rotated == rot_fake_pred).sum().item() / rot_fake_pred.size(0)\n",
    "\n",
    "        real_aux_logits, _ = torch.chunk(aux_logits, 2, dim=0)\n",
    "        real_aux_logits = real_aux_logits[:bs]\n",
    "\n",
    "        is_label_available, _ = torch.chunk(is_label_available, 2, dim=0)\n",
    "        is_label_available = is_label_available.squeeze(1)[:bs].unsqueeze(1)\n",
    "\n",
    "        class_loss_real = losses.weighted_cross_entropy(\n",
    "            real_labels, real_aux_logits, weights=is_label_available)\n",
    "\n",
    "        d_loss += class_loss_real * 1.0\n",
    "        d_loss.backward(retain_graph=True)\n",
    "        opt_dis.step()\n",
    "\n",
    "        g_loss += fake_loss * 0.2\n",
    "        g_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        writer.add_scalar('loss/total_G_loss', g_loss.item(), n_iter)\n",
    "        writer.add_scalar('loss/total_D_loss', d_loss.item(), n_iter)\n",
    "        writer.add_scalar('loss/real_loss', real_loss.item(), n_iter)\n",
    "        writer.add_scalar('loss/fake_loss', fake_loss.item(), n_iter)\n",
    "        writer.add_scalar('loss/G_loss', g_loss.item() - fake_loss.item(), n_iter)\n",
    "        writer.add_scalar('loss/D_loss', d_loss.item() - real_loss.item() -\n",
    "                          class_loss_real.item(), n_iter)\n",
    "\n",
    "        writer.add_scalar('accuracy/real', accuracy_real, n_iter)\n",
    "        writer.add_scalar('accuracy/fake', accuracy_fake, n_iter)\n",
    "        writer.add_scalar(\"loss/class_loss_real\", class_loss_real)\n",
    "        writer.add_scalar(\"label_frac\", torch.mean(is_label_available))\n",
    "\n",
    "        # ==================== End of 1 iteration. ====================\n",
    "\n",
    "        if n_iter % args.log_interval == 0:\n",
    "            tqdm.tqdm.write(\n",
    "                'iteration: {:07d}/{:07d}, loss gen: {:05f}, loss dis {:05f}'.format(\n",
    "                    n_iter, args.max_iteration, g_loss.item(), d_loss.item()))\n",
    "\n",
    "        if n_iter % args.checkpoint_interval == 0:\n",
    "            #Save checkpoints!\n",
    "            utils.save_checkpoints(args, n_iter, gen, opt_gen, dis, opt_dis, weight_path)\n",
    "            utils.save_img(fixed_img_list, fixed_label_list, fixed_z, gen,\n",
    "                           32, 28, img_path, n_iter, device=dev)\n",
    "    if args.test:\n",
    "        shutil.rmtree(args.results_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/userC/yonggyu/data/vgg_3-shot/3-shot\n",
      "vgg data_loader\n",
      "selecting model\n"
     ]
    }
   ],
   "source": [
    "    weight_path, img_path, loss_path = directory_path(args)\n",
    "    writer = SummaryWriter(loss_path)\n",
    "\n",
    "    # CUDA setting\n",
    "    if not torch.cuda.is_available():\n",
    "        raise ValueError(\"Should buy GPU!\")\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # dataloading\n",
    "    train_loader, s_dlen, _n_cls = data_loader(args)\n",
    "\n",
    "    fixed_z = torch.randn(400, 10, 128)\n",
    "    fixed_img_list, fixed_label_list = pick_fixed_img(args, train_loader, 400)\n",
    "\n",
    "    # initialize model\n",
    "    gen, dis = select_model(args, _n_cls)\n",
    "\n",
    "    opt_gen = optim.Adam(gen.parameters(), args.lr, (args.beta1, args.beta2))\n",
    "    opt_dis = optim.Adam(dis.parameters(), args.lr, (args.beta1, args.beta2))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    bs = args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yonggyu/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "        if n_iter >= args.lr_decay_start:\n",
    "            decay_lr(opt_gen, args.max_iteration, args.lr_decay_start, args.lr)\n",
    "            decay_lr(opt_dis, args.max_iteration, args.lr_decay_start, args.lr)\n",
    "\n",
    "        # ==================== Beginning of 1 iteration. ====================\n",
    "        _l_g = .0\n",
    "        cumulative_loss_dis = .0\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        opt_dis.zero_grad()\n",
    "\n",
    "        real_images, real_y = sample_from_data(args, dev, train_loader)\n",
    "        fake_images, pseudo_y, _ = sample_from_gen(args, dev, _n_cls, gen)\n",
    "\n",
    "        real_y = real_y.cuda()\n",
    "        pseudo_y = pseudo_y.cuda()\n",
    "\n",
    "        real_labels = torch.FloatTensor(real_y.size(0), _n_cls).cuda()\n",
    "        fake_labels = torch.FloatTensor(real_y.size(0), _n_cls).cuda()\n",
    "\n",
    "        real_labels.zero_()\n",
    "        fake_labels.zero_()\n",
    "\n",
    "        real_labels.scatter_(1, real_y.unsqueeze(1), 1)\n",
    "        fake_labels.scatter_(1, pseudo_y.unsqueeze(1), 1)\n",
    "\n",
    "        rotated_bs = bs // 2\n",
    "        num_rot_examples = rotated_bs // NUM_ROTATIONS\n",
    "\n",
    "        all_features, all_labels = utils.merge_with_rotation_data(\n",
    "            real_images, fake_images, real_labels, fake_labels, num_rot_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yonggyu/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "        d_predictions_d, d_logits_d, rot_logits_d, aux_logits_d, is_label_available_d = dis. \\\n",
    "            discriminator_with_additonal_heads(x=all_features.detach(), y=all_labels.detach())\n",
    "\n",
    "        expected_batch_size = 2 * bs\n",
    "        expected_batch_size += 2 * (NUM_ROTATIONS - 1) * num_rot_examples\n",
    "\n",
    "        if d_logits_d.shape[0] != expected_batch_size:\n",
    "            raise ValueError(\"Batch size unexpected: got %r expected %r\" % (\n",
    "                d_logits_d.shape[0], expected_batch_size))\n",
    "\n",
    "        prob_real_d, prob_fake_d = torch.chunk(d_predictions_d, 2, dim=0)\n",
    "        prob_real_d, prob_fake_d = prob_real_d[:bs], prob_fake_d[:bs]\n",
    "\n",
    "        logits_real_d, logits_fake_d = torch.chunk(d_logits_d, 2, dim=0)\n",
    "        logits_real_d, logits_fake_d = logits_real_d[:bs], logits_fake_d[:bs]\n",
    "\n",
    "        d_loss, _, _, _ = losses.hinge_losses(\n",
    "            d_real=prob_real_d, d_fake=prob_fake_d,\n",
    "            d_real_logits=logits_real_d, d_fake_logits=logits_fake_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yonggyu/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "        d_predictions, d_logits, rot_logits, aux_logits, is_label_available = \\\n",
    "            dis.discriminator_with_additonal_heads(x=all_features, y=all_labels)\n",
    "\n",
    "        if d_logits.shape[0] != expected_batch_size:\n",
    "            raise ValueError(\"Batch size unexpected: got %r expected %r\" % (\n",
    "                d_logits.shape[0], expected_batch_size))\n",
    "\n",
    "        prob_real, prob_fake = torch.chunk(d_predictions, 2, dim=0)\n",
    "        prob_real, prob_fake = prob_real[:bs], prob_fake[:bs]\n",
    "\n",
    "        logits_real, logits_fake = torch.chunk(d_logits, 2, dim=0)\n",
    "        logits_real, logits_fake = logits_real[:bs], logits_fake[:bs]\n",
    "\n",
    "        _, _, _, g_loss = losses.hinge_losses(\n",
    "            d_real=prob_real, d_fake=prob_fake,\n",
    "            d_real_logits=logits_real, d_fake_logits=logits_fake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1819, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "        rot_real_logits, rot_fake_logits = torch.chunk(rot_logits, 2, dim=0)\n",
    "        rot_real_logits = rot_real_logits[-rotated_bs:]\n",
    "        rot_fake_logits = rot_fake_logits[-rotated_bs:]\n",
    "\n",
    "        labels_rotated = torch.tensor(list(range(NUM_ROTATIONS))).repeat(num_rot_examples)\n",
    "\n",
    "        fake_loss = criterion(rot_fake_logits, labels_rotated)\n",
    "        real_loss = criterion(rot_real_logits, labels_rotated)\n",
    "\n",
    "        d_loss += real_loss * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "        rot_real_pred = torch.argmax(rot_real_logits, dim=1, keepdim=True)\n",
    "        rot_fake_pred = torch.argmax(rot_fake_logits, dim=1, keepdim=True)\n",
    "\n",
    "        accuracy_real = (labels_rotated == rot_real_pred).sum().item() / rot_real_pred.size(0)\n",
    "        accuracy_fake = (labels_rotated == rot_fake_pred).sum().item() / rot_fake_pred.size(0)\n",
    "\n",
    "        real_aux_logits, _ = torch.chunk(aux_logits, 2, dim=0)\n",
    "        real_aux_logits = real_aux_logits[:bs]\n",
    "\n",
    "        is_label_available, _ = torch.chunk(is_label_available, 2, dim=0)\n",
    "        is_label_available = is_label_available.squeeze(1)[:bs].unsqueeze(1)\n",
    "\n",
    "        class_loss_real = losses.weighted_cross_entropy(\n",
    "            real_labels, real_aux_logits, weights=is_label_available)\n",
    "\n",
    "        d_loss += class_loss_real * 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_label_available.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.zeros(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat([a, b], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0034, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_loss_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_loss_real = losses.weighted_cross_entropy(\n",
    "            real_labels, real_aux_logits, weights=is_label_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_aux_probs = F.softmax(real_aux_logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0034, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(-real_labels * torch.log(real_aux_probs) * is_label_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0034, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(-real_labels * torch.log(real_aux_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0017, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(-real_labels * torch.log(real_aux_probs) * c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_cross_entropy(real_labels, real_aux_logits, weights):\n",
    "    real_aux_probs = F.softmax(real_aux_logits, dim=1)\n",
    "    loss = torch.mean(-real_labels * torch.log(real_aux_probs) * weights)\n",
    "    return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
